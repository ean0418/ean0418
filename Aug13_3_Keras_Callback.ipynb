{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxW41BNfUXzeJdBwZVjCGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ean0418/ean0418/blob/main/Aug13_3_Keras_Callback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 콜백 (Callback)\n",
        "\n",
        "Model을 학습시킬 때 부가적으로 옵션을 넣어서 수행할 수 있도록 도와주는 객체\n",
        "\n",
        "모델 학습시 사용하는 .fit() 함수에 callbacks라는 파라미터로 지정할 수 있음\n",
        "\n",
        "딥러닝 모델이 과적합되기 시작하면 새로운 데이터에서의 예측 성능을 신뢰하기가 어려워지기에 학습 시 손실이 더이상 감소하지 않으면 학습을 중단하는 방법으로 사용\n",
        "\n",
        "=> 특정 조건에서 자동으로 실행되는 기능!"
      ],
      "metadata": {
        "id": "eL62D-huJoUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_XyhInJJZ67"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras 내장 datasets에서 mnist 불러오기\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "bXRlIVUFKebA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data 정규화 0 ~ 1 사이로\n",
        "x_train = x_train / x_train.max()\n",
        "x_test = x_test / 255."
      ],
      "metadata": {
        "id": "g2N1bSwTKi2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 생성\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HnXlE09K0Nt",
        "outputId": "c111f7a8-61e6-45fe-daf6-54f3cf76f3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UQnteWEALRRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 체크포인트 (Model Checkpoint)\n",
        "\n",
        "epoch 별로 model의 가중치를 저장하는 역할\n",
        "\n",
        "체크포인트 하이퍼파라미터\n",
        "\n",
        "- filepath : 체크포인트를 저장하는 경로를 지정\n",
        "- monitor : 저장 시 기준이 되는 지표를 설정\n",
        "- save_best_only : monitor 기준 가장 높은 epoch만 저장할지 or epoch마다 저장할지 여부(True, False)\n",
        "- verbose : epoch마다 저장 여부를 알려주는 로그메시지 출력여부 (1, 0)\n",
        "- save_weights_only : 가중치만 저장할지 여부(True, False) => .ckpt 파일에서만 사용 가능\n",
        "\n",
        "Tensorflow가 업그레이드 되면서 .keras확장자가 새로 생겨남\n"
      ],
      "metadata": {
        "id": "d6zDBjW_LsN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 설정\n",
        "checkPoint = keras.callbacks.ModelCheckpoint(\n",
        "    filepath = 'checkPoint.keras', # .ckpt => .keras : 모델의 가중치 체크포인트 저장 파일\n",
        "    # 이 파일을 통해서 재학습이 가능, 불필요한 정보도 있어서 파일의 크기가 크고 무거움\n",
        "    save_best_only = True,\n",
        "    # True : monitor 되고 있는 값 기준으로 가장 뛰어난 epoch 모델이 저장\n",
        "    # False : epoch마다 모델이 filepath{epoch} 형태로 저장\n",
        "    monitor = 'val_loss', # model을 저장할 때 기준이 되는 값을 지정\n",
        "    # 테스트 데이터셋을 기준으로 loss가 가장 적을 때 저장하려면 'val_loss'\n",
        "    # 학습 데이터셋을 기준으로 loss가 가정 적을 때 저장하려면 'loss'\n",
        "    verbose = 1, # 1이면 모델 저장시 문구가 뜸, 0이면 문구 없이 저장만\n",
        "    # save_weights_only = True\n",
        ")"
      ],
      "metadata": {
        "id": "BDrtBK4wLh5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "          epochs=10, callbacks=[checkPoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvaFPv8HObug",
        "outputId": "40c2b58b-ede5-4695-9cf8-d110cabdb5d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1871/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8874 - loss: 0.3849\n",
            "Epoch 1: val_loss improved from inf to 0.12825, saving model to checkPoint.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8875 - loss: 0.3844 - val_accuracy: 0.9595 - val_loss: 0.1283\n",
            "Epoch 2/10\n",
            "\u001b[1m1869/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.0946\n",
            "Epoch 2: val_loss improved from 0.12825 to 0.08883, saving model to checkPoint.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.0946 - val_accuracy: 0.9726 - val_loss: 0.0888\n",
            "Epoch 3/10\n",
            "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0645\n",
            "Epoch 3: val_loss improved from 0.08883 to 0.07889, saving model to checkPoint.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0645 - val_accuracy: 0.9772 - val_loss: 0.0789\n",
            "Epoch 4/10\n",
            "\u001b[1m1867/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0456\n",
            "Epoch 4: val_loss did not improve from 0.07889\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0456 - val_accuracy: 0.9772 - val_loss: 0.0798\n",
            "Epoch 5/10\n",
            "\u001b[1m1865/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0376\n",
            "Epoch 5: val_loss did not improve from 0.07889\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0376 - val_accuracy: 0.9754 - val_loss: 0.0847\n",
            "Epoch 6/10\n",
            "\u001b[1m1865/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9903 - loss: 0.0298\n",
            "Epoch 6: val_loss improved from 0.07889 to 0.07747, saving model to checkPoint.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9902 - loss: 0.0298 - val_accuracy: 0.9784 - val_loss: 0.0775\n",
            "Epoch 7/10\n",
            "\u001b[1m1872/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0234\n",
            "Epoch 7: val_loss improved from 0.07747 to 0.07651, saving model to checkPoint.keras\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9925 - loss: 0.0234 - val_accuracy: 0.9802 - val_loss: 0.0765\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0204\n",
            "Epoch 8: val_loss did not improve from 0.07651\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0204 - val_accuracy: 0.9774 - val_loss: 0.0866\n",
            "Epoch 9/10\n",
            "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0189\n",
            "Epoch 9: val_loss did not improve from 0.07651\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0189 - val_accuracy: 0.9772 - val_loss: 0.0839\n",
            "Epoch 10/10\n",
            "\u001b[1m1874/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9951 - loss: 0.0149\n",
            "Epoch 10: val_loss did not improve from 0.07651\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0149 - val_accuracy: 0.9802 - val_loss: 0.0835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b3857577a60>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 적용 전 모델\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f'loss : {loss}, acc : {acc}')\n",
        "\n",
        "model.load_weights('checkPoint.keras')\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print(f'loss : {loss}, acc : {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe7BfZ51O5Io",
        "outputId": "6f38d6b7-2635-415a-d6a2-c4f9b0555344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0890\n",
            "loss : 0.08354642242193222, acc : 0.9801999926567078\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0919\n",
            "loss : 0.07650627195835114, acc : 0.9801999926567078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAfZUtRdQP17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}